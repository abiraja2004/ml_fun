{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new version of PyGraphistry is available (installed=0.9.17 latest=0.9.30).\n",
      "Ken Cavagnolo \n",
      "last updated: Sun Sep 11 2016 \n",
      "\n",
      "CPython 2.7.10\n",
      "IPython 4.1.1\n",
      "\n",
      "numpy 1.11.1\n",
      "scipy 0.18.0\n",
      "pandas 0.18.1\n",
      "scikit-learn 0.17.1\n",
      "theano 0.8.2\n",
      "xgboost 0.6a2\n",
      "matplotlib 1.5.0\n",
      "seaborn 0.8.dev0\n",
      "plotly 1.9.0\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)\n",
      "system     : Darwin\n",
      "release    : 15.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : DrGonzo.local\n",
      "Git hash   : a32b6437f83e4bfe41624ea4b826e21f65815d76\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# basics #\n",
    "##########\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import itertools\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "###########\n",
    "# science #\n",
    "###########\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rseed = random.seed(42)\n",
    "\n",
    "######\n",
    "# ml #\n",
    "######\n",
    "\n",
    "import xgboost as xgb\n",
    "import theano as thno\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn import pipeline\n",
    "from sklearn import feature_selection\n",
    "\n",
    "#################\n",
    "# visualization #\n",
    "#################\n",
    "\n",
    "# plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs import *\n",
    "import cufflinks as cf\n",
    "tls.set_credentials_file(username=os.environ.get('PLOTLY_USERNAME'), api_key=os.environ.get('PLOTLY_APIKEY'))\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='pearl')\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "mpl.rcParams['figure.figsize']=(12.0,4.0)\n",
    "%matplotlib inline\n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted', n_colors=15, desat=None)\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "#graphistry\n",
    "import graphistry\n",
    "graphistry.register(key=os.environ.get('GRAPHISTRY_APIKEY'))\n",
    "\n",
    "############\n",
    "# sys info #\n",
    "############\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Ken Cavagnolo\" -n -u -v -m -h -g -p numpy,scipy,pandas,\\\n",
    "scikit-learn,theano,xgboost,\\\n",
    "matplotlib,seaborn,plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "def nonlin(x, deriv=False):\n",
    "    if deriv==True:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data\n",
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "y = np.array([[0,0,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random initial weights\n",
    "syn0 = 2*np.random.random((3,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.56666344]\n",
      " [-0.62705718]\n",
      " [ 0.13628696]]\n",
      "[[ 0.7600985 ]\n",
      " [-0.59640514]\n",
      " [ 0.10740135]]\n",
      "[[ 0.9279025 ]\n",
      " [-0.57977861]\n",
      " [ 0.05430837]]\n",
      "[[ 1.07814177]\n",
      " [-0.57031076]\n",
      " [-0.01051622]]\n",
      "[[ 1.21578491]\n",
      " [-0.56390798]\n",
      " [-0.07973971]]\n",
      "[[ 1.3436899 ]\n",
      " [-0.55848675]\n",
      " [-0.14943214]]\n",
      "[[ 1.46353943]\n",
      " [-0.55310749]\n",
      " [-0.21759968]]\n",
      "[[ 1.57639617]\n",
      " [-0.54742002]\n",
      " [-0.28329733]]\n",
      "[[ 1.68299765]\n",
      " [-0.54135498]\n",
      " [-0.34613461]]\n",
      "[[ 1.78390682]\n",
      " [-0.53496335]\n",
      " [-0.4060088 ]]\n",
      "[[ 1.87958736]\n",
      " [-0.52833737]\n",
      " [-0.46296325]]\n",
      "[[ 1.97044117]\n",
      " [-0.52157412]\n",
      " [-0.51711259]]\n",
      "[[ 2.05682709]\n",
      " [-0.51476031]\n",
      " [-0.56860353]]\n",
      "[[ 2.13907057]\n",
      " [-0.50796746]\n",
      " [-0.61759413]]\n",
      "[[ 2.21746904]\n",
      " [-0.50125166]\n",
      " [-0.66424301]]\n",
      "[[ 2.29229515]\n",
      " [-0.49465522]\n",
      " [-0.70870382]]\n",
      "[[ 2.36379916]\n",
      " [-0.48820891]\n",
      " [-0.75112243]]\n",
      "[[ 2.43221082]\n",
      " [-0.48193415]\n",
      " [-0.79163573]]\n",
      "[[ 2.49774106]\n",
      " [-0.47584503]\n",
      " [-0.83037129]]\n",
      "[[ 2.56058349]\n",
      " [-0.4699499 ]\n",
      " [-0.86744745]]\n",
      "[[ 2.62091587]\n",
      " [-0.46425274]\n",
      " [-0.90297366]]\n",
      "[[ 2.67890144]\n",
      " [-0.45875426]\n",
      " [-0.937051  ]]\n",
      "[[ 2.73469016]\n",
      " [-0.4534527 ]\n",
      " [-0.96977272]]\n",
      "[[ 2.7884199 ]\n",
      " [-0.44834454]\n",
      " [-1.00122479]]\n",
      "[[ 2.84021748]\n",
      " [-0.44342496]\n",
      " [-1.03148651]]\n",
      "[[ 2.89019967]\n",
      " [-0.43868829]\n",
      " [-1.06063098]]\n",
      "[[ 2.93847408]\n",
      " [-0.43412829]\n",
      " [-1.08872567]]\n",
      "[[ 2.98514002]\n",
      " [-0.42973835]\n",
      " [-1.11583288]]\n",
      "[[ 3.03028917]\n",
      " [-0.42551171]\n",
      " [-1.14201017]]\n",
      "[[ 3.07400632]\n",
      " [-0.42144157]\n",
      " [-1.16731076]]\n",
      "[[ 3.11636997]\n",
      " [-0.41752119]\n",
      " [-1.19178392]]\n",
      "[[ 3.15745284]\n",
      " [-0.41374395]\n",
      " [-1.21547529]]\n",
      "[[ 3.19732244]\n",
      " [-0.4101034 ]\n",
      " [-1.23842722]]\n",
      "[[ 3.23604147]\n",
      " [-0.40659332]\n",
      " [-1.260679  ]]\n",
      "[[ 3.27366824]\n",
      " [-0.40320771]\n",
      " [-1.28226718]]\n",
      "[[ 3.31025707]\n",
      " [-0.39994081]\n",
      " [-1.30322575]]\n",
      "[[ 3.34585859]\n",
      " [-0.39678712]\n",
      " [-1.32358636]]\n",
      "[[ 3.38052005]\n",
      " [-0.39374141]\n",
      " [-1.34337853]]\n",
      "[[ 3.41428561]\n",
      " [-0.39079867]\n",
      " [-1.36262984]]\n",
      "[[ 3.44719658]\n",
      " [-0.38795416]\n",
      " [-1.38136603]]\n",
      "[[ 3.47929165]\n",
      " [-0.38520336]\n",
      " [-1.39961118]]\n",
      "[[ 3.51060708]\n",
      " [-0.382542  ]\n",
      " [-1.41738785]]\n",
      "[[ 3.54117692]\n",
      " [-0.37996602]\n",
      " [-1.43471719]]\n",
      "[[ 3.57103314]\n",
      " [-0.37747158]\n",
      " [-1.45161904]]\n",
      "[[ 3.60020581]\n",
      " [-0.37505504]\n",
      " [-1.46811202]]\n",
      "[[ 3.62872324]\n",
      " [-0.37271294]\n",
      " [-1.48421366]]\n",
      "[[ 3.65661211]\n",
      " [-0.37044202]\n",
      " [-1.49994044]]\n",
      "[[ 3.68389757]\n",
      " [-0.36823918]\n",
      " [-1.51530789]]\n",
      "[[ 3.71060338]\n",
      " [-0.36610149]\n",
      " [-1.53033065]]\n",
      "[[ 3.73675197]\n",
      " [-0.36402616]\n",
      " [-1.54502253]]\n",
      "[[ 3.76236457]\n",
      " [-0.36201058]\n",
      " [-1.55939658]]\n",
      "[[ 3.78746126]\n",
      " [-0.36005223]\n",
      " [-1.57346512]]\n",
      "[[ 3.81206106]\n",
      " [-0.35814875]\n",
      " [-1.58723984]]\n",
      "[[ 3.83618202]\n",
      " [-0.35629791]\n",
      " [-1.60073177]]\n",
      "[[ 3.85984125]\n",
      " [-0.35449756]\n",
      " [-1.61395138]]\n",
      "[[ 3.883055  ]\n",
      " [-0.35274568]\n",
      " [-1.62690859]]\n",
      "[[ 3.90583871]\n",
      " [-0.35104037]\n",
      " [-1.63961283]]\n",
      "[[ 3.92820708]\n",
      " [-0.34937978]\n",
      " [-1.65207305]]\n",
      "[[ 3.95017406]\n",
      " [-0.34776219]\n",
      " [-1.66429773]]\n",
      "[[ 3.97175297]\n",
      " [-0.34618596]\n",
      " [-1.67629499]]\n",
      "[[ 3.9929565]\n",
      " [-0.3446495]\n",
      " [-1.6880725]]\n",
      "[[ 4.01379673]\n",
      " [-0.34315134]\n",
      " [-1.6996376 ]]\n",
      "[[ 4.0342852 ]\n",
      " [-0.34169005]\n",
      " [-1.71099728]]\n",
      "[[ 4.05443294]\n",
      " [-0.34026428]\n",
      " [-1.7221582 ]]\n",
      "[[ 4.07425046]\n",
      " [-0.33887274]\n",
      " [-1.73312671]]\n",
      "[[ 4.09374783]\n",
      " [-0.3375142 ]\n",
      " [-1.7439089 ]]\n",
      "[[ 4.11293467]\n",
      " [-0.33618749]\n",
      " [-1.75451055]]\n",
      "[[ 4.13182021]\n",
      " [-0.33489149]\n",
      " [-1.76493721]]\n",
      "[[ 4.15041325]\n",
      " [-0.33362514]\n",
      " [-1.77519419]]\n",
      "[[ 4.16872225]\n",
      " [-0.33238742]\n",
      " [-1.78528656]]\n",
      "[[ 4.18675532]\n",
      " [-0.33117735]\n",
      " [-1.79521919]]\n",
      "[[ 4.20452022]\n",
      " [-0.329994  ]\n",
      " [-1.80499672]]\n",
      "[[ 4.22202441]\n",
      " [-0.32883648]\n",
      " [-1.81462363]]\n",
      "[[ 4.23927507]\n",
      " [-0.32770395]\n",
      " [-1.82410419]]\n",
      "[[ 4.25627905]\n",
      " [-0.32659558]\n",
      " [-1.83344251]]\n",
      "[[ 4.27304299]\n",
      " [-0.3255106 ]\n",
      " [-1.84264254]]\n",
      "[[ 4.28957322]\n",
      " [-0.32444826]\n",
      " [-1.85170807]]\n",
      "[[ 4.30587588]\n",
      " [-0.32340785]\n",
      " [-1.86064273]]\n",
      "[[ 4.32195684]\n",
      " [-0.32238867]\n",
      " [-1.86945003]]\n",
      "[[ 4.33782177]\n",
      " [-0.32139007]\n",
      " [-1.87813333]]\n",
      "[[ 4.35347613]\n",
      " [-0.32041142]\n",
      " [-1.88669588]]\n",
      "[[ 4.36892517]\n",
      " [-0.31945212]\n",
      " [-1.89514079]]\n",
      "[[ 4.38417397]\n",
      " [-0.31851157]\n",
      " [-1.90347106]]\n",
      "[[ 4.39922743]\n",
      " [-0.31758923]\n",
      " [-1.9116896 ]]\n",
      "[[ 4.41409024]\n",
      " [-0.31668456]\n",
      " [-1.91979918]]\n",
      "[[ 4.42876698]\n",
      " [-0.31579703]\n",
      " [-1.92780251]]\n",
      "[[ 4.44326204]\n",
      " [-0.31492616]\n",
      " [-1.93570217]]\n",
      "[[ 4.45757965]\n",
      " [-0.31407147]\n",
      " [-1.94350066]]\n",
      "[[ 4.47172394]\n",
      " [-0.31323249]\n",
      " [-1.95120041]]\n",
      "[[ 4.48569885]\n",
      " [-0.31240879]\n",
      " [-1.95880375]]\n",
      "[[ 4.49950824]\n",
      " [-0.31159995]\n",
      " [-1.96631294]]\n",
      "[[ 4.5131558 ]\n",
      " [-0.31080554]\n",
      " [-1.97373015]]\n",
      "[[ 4.52664513]\n",
      " [-0.31002518]\n",
      " [-1.9810575 ]]\n",
      "[[ 4.5399797 ]\n",
      " [-0.30925848]\n",
      " [-1.98829701]]\n",
      "[[ 4.55316288]\n",
      " [-0.30850508]\n",
      " [-1.99545067]]\n",
      "[[ 4.56619792]\n",
      " [-0.30776463]\n",
      " [-2.00252037]]\n",
      "[[ 4.57908798]\n",
      " [-0.30703678]\n",
      " [-2.00950797]]\n",
      "[[ 4.59183612]\n",
      " [-0.30632121]\n",
      " [-2.01641525]]\n",
      "[[ 4.6044453 ]\n",
      " [-0.30561759]\n",
      " [-2.02324395]]\n",
      "[[ 4.61691841]\n",
      " [-0.30492562]\n",
      " [-2.02999575]]\n",
      "Output After Training:\n",
      "[[ 0.11678398]\n",
      " [ 0.0887607 ]\n",
      " [ 0.92964189]\n",
      " [ 0.90683461]]\n"
     ]
    }
   ],
   "source": [
    "# train net\n",
    "for iter in xrange(100):\n",
    "\n",
    "    # forward propagation\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "\n",
    "    # how much did we miss?\n",
    "    l1_err = y - l1\n",
    "\n",
    "    # multiply how much we missed by the \n",
    "    # slope of the sigmoid at the values in l1\n",
    "    l1_delta = l1_err * nonlin(l1,True)\n",
    "\n",
    "    # update weights\n",
    "    syn0 += np.dot(l0.T, l1_delta)\n",
    "    print syn0\n",
    "\n",
    "print \"Output After Training:\"\n",
    "print l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "datadir = '/Users/cavagnolo/ml_fun/pima_indians/data/'\n",
    "dataset = np.loadtxt(datadir+\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s - loss: 0.6806 - acc: 0.6354     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.6637 - acc: 0.6510     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.6582 - acc: 0.6380     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.6481 - acc: 0.6510     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.6416 - acc: 0.6497     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.6304 - acc: 0.6693     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.6216 - acc: 0.6628     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.6150 - acc: 0.6823     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.6076 - acc: 0.6914     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.6050 - acc: 0.6836     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.5937 - acc: 0.6888     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.5947 - acc: 0.6823     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.5918 - acc: 0.6979     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.5817 - acc: 0.7005     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.5908 - acc: 0.6914     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.5770 - acc: 0.6927     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.5815 - acc: 0.7096     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.5801 - acc: 0.6979     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.5810 - acc: 0.6953     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.5748 - acc: 0.6953     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.5746 - acc: 0.7005     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.5720 - acc: 0.7109     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.5701 - acc: 0.7122     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.5730 - acc: 0.6992     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s - loss: 0.5719 - acc: 0.7031     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.5697 - acc: 0.6992     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.5692 - acc: 0.6836     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.5733 - acc: 0.7096     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.5644 - acc: 0.7018     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.5646 - acc: 0.7031     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.5615 - acc: 0.7227     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.5632 - acc: 0.7005     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.5595 - acc: 0.7044     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.5582 - acc: 0.7161     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.5650 - acc: 0.7135     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.5582 - acc: 0.7109     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.5582 - acc: 0.7122     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.5641 - acc: 0.7096     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.5576 - acc: 0.7135     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.5537 - acc: 0.7240     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.5604 - acc: 0.7161     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.5512 - acc: 0.7188     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.5518 - acc: 0.7305     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.5519 - acc: 0.7227     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.5502 - acc: 0.7318     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.5468 - acc: 0.7148     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.5469 - acc: 0.7370     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.5478 - acc: 0.7188     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.5457 - acc: 0.7161     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.5440 - acc: 0.7266     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.5516 - acc: 0.7240     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.5403 - acc: 0.7396     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.5383 - acc: 0.7253     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.5394 - acc: 0.7435     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.5406 - acc: 0.7344     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.5425 - acc: 0.7357     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.5345 - acc: 0.7305     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.5350 - acc: 0.7409     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.5407 - acc: 0.7227     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.5322 - acc: 0.7396     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.5257 - acc: 0.7396     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.5334 - acc: 0.7344     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.5329 - acc: 0.7318     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.5261 - acc: 0.7435     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.5263 - acc: 0.7396     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.5218 - acc: 0.7370     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.5242 - acc: 0.7630     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.5223 - acc: 0.7539     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.5174 - acc: 0.7487     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.5198 - acc: 0.7539     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.5152 - acc: 0.7565     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.5167 - acc: 0.7539     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.5148 - acc: 0.7487     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.5153 - acc: 0.7487     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.5176 - acc: 0.7448     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.5158 - acc: 0.7344     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.5104 - acc: 0.7591     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.5046 - acc: 0.7526     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.5098 - acc: 0.7565     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.5069 - acc: 0.7656     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.5126 - acc: 0.7630     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.5080 - acc: 0.7604     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.5039 - acc: 0.7695     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.5004 - acc: 0.7656     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.5069 - acc: 0.7526     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.5064 - acc: 0.7539     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.5004 - acc: 0.7682     \n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s - loss: 0.4992 - acc: 0.7643     \n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s - loss: 0.5027 - acc: 0.7461     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.5024 - acc: 0.7643     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.5138 - acc: 0.7487     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.4958 - acc: 0.7591     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.4940 - acc: 0.7669     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.4970 - acc: 0.7591     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.4926 - acc: 0.7617     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.4924 - acc: 0.7604     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.4984 - acc: 0.7786     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.4972 - acc: 0.7630     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.4970 - acc: 0.7617     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.4935 - acc: 0.7734     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.4891 - acc: 0.7617     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.4957 - acc: 0.7669     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.4940 - acc: 0.7552     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.4907 - acc: 0.7604     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.4878 - acc: 0.7656     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.4876 - acc: 0.7643     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.4849 - acc: 0.7734     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.4831 - acc: 0.7773     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.4911 - acc: 0.7565     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.4855 - acc: 0.7656     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.4908 - acc: 0.7682     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.4807 - acc: 0.7604     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.4908 - acc: 0.7539     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.4819 - acc: 0.7630     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.4816 - acc: 0.7721     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.4809 - acc: 0.7708     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.4777 - acc: 0.7656     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.4865 - acc: 0.7604     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.4800 - acc: 0.7604     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.4947 - acc: 0.7578     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.4819 - acc: 0.7656     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.4857 - acc: 0.7747     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.4749 - acc: 0.7721     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.4772 - acc: 0.7604     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.4778 - acc: 0.7734     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.4800 - acc: 0.7604     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.4844 - acc: 0.7565     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.4763 - acc: 0.7617     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.4743 - acc: 0.7695     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.4728 - acc: 0.7643     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.4762 - acc: 0.7747     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.4689 - acc: 0.7852     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.4683 - acc: 0.7695     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.4731 - acc: 0.7617     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.4692 - acc: 0.7669     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.4819 - acc: 0.7682     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.4723 - acc: 0.7786     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.4688 - acc: 0.7643     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.4696 - acc: 0.7695     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.4673 - acc: 0.7747     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.4696 - acc: 0.7799     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.4653 - acc: 0.7695     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.4617 - acc: 0.7812     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.4727 - acc: 0.7708     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.4715 - acc: 0.7878     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.4769 - acc: 0.7656     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.4762 - acc: 0.7682     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.4630 - acc: 0.7656     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.4691 - acc: 0.7826     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.4674 - acc: 0.7721     \n",
      " 32/768 [>.............................] - ETA: 0sacc: 78.26%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
