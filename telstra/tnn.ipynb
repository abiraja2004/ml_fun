{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_ksmod.csv').fillna(0)\n",
    "test = pd.read_csv('data/test_ksmod.csv').fillna(0)\n",
    "sample = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', shape=[None, train.iloc[:, 3:].shape[1]])\n",
    "y_ = tf.placeholder('float', shape=[None, 3])\n",
    "l2 = tf.placeholder('float')\n",
    "hidden1 = 2000\n",
    "hidden2 = 100\n",
    "\n",
    "with tf.name_scope('hidden1'):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([train.iloc[:, 3:].shape[1], hidden1],\n",
    "                            stddev=1.0 / np.sqrt(float(train.iloc[:, 3:].shape[1]))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([hidden1]),\n",
    "                         name='biases')\n",
    "    hidden1_tensor = tf.nn.relu(tf.matmul(x, weights) + biases)\n",
    "    reg_hidden1 = tf.nn.l2_loss(weights) + tf.nn.l2_loss(biases)\n",
    "\n",
    "with tf.name_scope('hidden2'):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([hidden1, hidden2],\n",
    "                            stddev=1.0 / np.sqrt(float(hidden1))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([hidden2]),\n",
    "                         name='biases')\n",
    "    hidden2_tensor = tf.nn.relu(tf.matmul(hidden1_tensor, weights) + biases)\n",
    "    reg_hidden2 = tf.nn.l2_loss(weights) + tf.nn.l2_loss(biases)\n",
    "\n",
    "with tf.name_scope('softmax_linear'):\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([hidden2, 3],\n",
    "                            stddev=1.0 / np.sqrt(float(hidden2))),\n",
    "        name='weights')\n",
    "    biases = tf.Variable(tf.zeros([3]),\n",
    "                         name='biases')\n",
    "    logits = tf.matmul(hidden2_tensor, weights) + biases\n",
    "    reg_hidden3 = tf.nn.l2_loss(weights) + tf.nn.l2_loss(biases)\n",
    "\n",
    "sess.run(tf.initialize_all_variables()) \n",
    "y = tf.nn.softmax(logits)\n",
    "cross_entropy = - tf.reduce_mean(y_ * tf.log(y) + 1e-15) + l2 * (reg_hidden1 + reg_hidden2 + reg_hidden3)\n",
    "train_step = tf.train.GradientDescentOptimizer(.001).minimize(cross_entropy)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(\n",
    "        train.iloc[:, 3:],\n",
    "        train.loc[:, 'fault_severity'],\n",
    "        test_size=0.3333)\n",
    "labels = tf.expand_dims(np.asarray(train.loc[:, 'fault_severity'].values, dtype='int32'), 1)\n",
    "indices = tf.expand_dims(tf.range(0, train.shape[0]), 1)\n",
    "concated = tf.concat(1, [indices, labels])\n",
    "train_onehot_labels = tf.sparse_to_dense(\n",
    "    concated, tf.pack([train.shape[0], sample.shape[1]-1]), 1.0, 0.0).eval()\n",
    "for i in range(train_x.shape[0]//batch_size):\n",
    "    train_step.run(\n",
    "        feed_dict={\n",
    "            x: train.iloc[batch_size*i:batch_size*(i+1), 3:].values,\n",
    "            y_: train_onehot_labels[batch_size*i:batch_size*(i+1), :],\n",
    "            l2: 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = y.eval(feed_dict={x: test.iloc[:, 2:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = pd.DataFrame({\n",
    "    'id': sample.loc[:, 'id'].values, \n",
    "    'predict_0': prob[:, 0],\n",
    "    'predict_1': prob[:, 1],\n",
    "    'predict_2': prob[:, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.to_csv('tnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
